package au.org.ala.checklist.lucene;

import au.org.ala.checklist.lucene.analyzer.LowerCaseKeywordAnalyzer;
import au.org.ala.data.model.ALAParsedName;
import au.org.ala.data.util.PhraseNameParser;
import java.io.BufferedReader;
import java.io.File;
import java.io.FileReader;
import java.io.IOException;
import java.io.InputStreamReader;
import java.util.HashSet;
import java.util.Set;
import java.util.TreeSet;
import java.util.regex.Pattern;

import javax.sql.DataSource;

import org.apache.commons.io.FileUtils;
import org.apache.commons.io.LineIterator;
import org.apache.commons.lang.StringUtils;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.apache.lucene.analysis.Analyzer;
import org.apache.lucene.analysis.KeywordAnalyzer;
import org.apache.lucene.analysis.SimpleAnalyzer;
import org.apache.lucene.document.Document;
import org.apache.lucene.document.Field;
import org.apache.lucene.document.Field.Index;
import org.apache.lucene.document.Field.Store;
import org.apache.lucene.index.IndexWriter;
import org.apache.lucene.index.Term;
import org.apache.lucene.index.IndexWriter.MaxFieldLength;
import org.apache.lucene.search.IndexSearcher;
import org.apache.lucene.search.TermQuery;
import org.apache.lucene.store.FSDirectory;
import org.gbif.ecat.model.ParsedName;
import org.gbif.ecat.parser.NameParser;
import org.gbif.file.CSVReader;
import au.org.ala.data.util.TaxonNameSoundEx;
//import org.springframework.context.ApplicationContext;
//import org.springframework.context.support.ClassPathXmlApplicationContext;
//import org.springframework.jdbc.core.JdbcTemplate;

import au.org.ala.data.util.RankType;
import org.gbif.ecat.voc.NameType;

/**
 * Creates the Lucene index based on the cb_names export generated by ChecklistBankExporter
 *
 * @author Natasha
 */
public class CBCreateLuceneIndex {

    protected String cbExportFile = "cb_name_usages.txt";
    protected String lexFile = "cb_lex_names.txt";
    protected String irmngFile = "irmng_classification.txt";
    protected String colFile = "col_common_names.txt";
    protected String afdFile = "/data/bie-staging/anbg/AFD-common-names.csv";
    protected String apniFile = "/data/bie-staging/anbg/APNI-common-names.csv";
    protected String taxonConeptName = "/data/bie-staging/anbg/taxonConcepts.txt";
    protected Log log = LogFactory.getLog(CBCreateLuceneIndex.class);
   // protected ApplicationContext context;
    protected DataSource dataSource;
   // protected JdbcTemplate dTemplate;
    private IndexSearcher idSearcher;
    //the position in the line for each of the required values
    //nub id\tparent nub id\tlsid\tsynonym id\tsynonym lsid\tname id\tcanonical name\tauthor\tportal rank id\trank\tlft\trgt\tkingdom id\tkingdom\tphylum id\tphylum\tclass id\tclass\torder id \torder\tfamily id\tfamily\tgenus id\tgenus\tspecies id\tspecies
    private final int POS_ID = 0;
    private final int POS_PARENT_ID = 1;
    private final int POS_LSID = 2;
    private final int POS_PARETN_LSID = 3;
    private final int POS_ACC_LSID = 4;
    private final int POS_NAME_LSID = 5;
    private final int POS_SCI_NAME =6;
    private final int POS_GENUS_OR_HIGHER = 7;
    private final int POS_SP_EPITHET = 8;
    private final int POS_INFRA_EPITHET=9;
    private final int POS_AUTHOR = 10;
    private final int POS_AUTHOR_YEAR = 11;
    private final int POS_RANK_ID = 12;
    private final int POS_RANK = 13;
    private final int POS_LFT = 14;
    private final int POS_RGT = 15;
    private final int POS_KID = 16;
    private final int POS_K = 17;
    private final int POS_PID = 18;
    private final int POS_P = 19;
    private final int POS_CID = 20;
    private final int POS_C = 21;
    private final int POS_OID = 22;
    private final int POS_O = 23;
    private final int POS_FID = 24;
    private final int POS_F = 25;
    private final int POS_GID = 26;
    private final int POS_G = 27;
    private final int POS_SID = 28;
    private final int POS_S = 29;

    //Fields that are being indexed or stored in the lucene index
    public enum IndexField {

        NAME("name"),
        NAMES("names"),
        ID("id"),
        RANK("rank"),
        SEARCHABLE_NAME("searchcan"),
        LSID("lsid"),
        HOMONYM("homonym"),
        ACCEPTED("synonym"),
        LEFT("left"),
        RIGHT("right"),
        COMMON_NAME("common");

        String name;

        IndexField(String name) {
            this.name = name;
        }

        public String toString() {
            return name;
        }
    };
    NameParser parser = new PhraseNameParser();
    Set<String> knownHomonyms = new HashSet<String>();
    private TaxonNameSoundEx tnse;

    public void init() throws Exception {
        //String[] locations = {"classpath*:au/org/ala/**/applicationContext-cb*.xml"};
        //context = new ClassPathXmlApplicationContext(locations);
        //dataSource = (DataSource) context.getBean("cbDataSource");
        //dTemplate = new JdbcTemplate(dataSource);
        tnse = new TaxonNameSoundEx();
        // init the known homonyms
        LineIterator lines = new LineIterator(new BufferedReader(
                new InputStreamReader(
                this.getClass().getClassLoader().getResource(
                "au/org/ala/propertystore/known_homonyms.txt").openStream(), "ISO-8859-1")));
        while (lines.hasNext()) {
            String line = lines.nextLine().trim();
            knownHomonyms.add(line.toUpperCase());
        }
    }

    /**
     * Creates the index from the specified checklist bank names usage export file into
     * the specified index directory.
     *
     * @param cbExportFile A cb export file as generated from the ChecklistBankExporter
     * @param lexFile
     * @param irmngFile
     * @param indexDir The directory in which the 2 indices will be created.
     * @throws Exception
     */
    public void createIndex(String exportsDir, String indexDir, boolean generateSciNames, boolean generateCommonNames) throws Exception {

        Analyzer analyzer = new LowerCaseKeywordAnalyzer();
        //generate the extra id index
        createExtraIdIndex(indexDir + File.separator + "id",new File(exportsDir + File.separator + "identifiers.txt"));
        if(generateSciNames){
            //Checklist Bank Main Index
            indexALA(createIndexWriter(new File(indexDir + File.separator + "cb"), analyzer), exportsDir + File.separator + "ala_concepts_dump.txt");//, exportsDir + File.separator + lexFile);
            //IRMNG index to aid in the resolving of homonyms
            IndexWriter irmngWriter = createIndexWriter(new File(indexDir + File.separator + "irmng"), analyzer);
            indexIRMNG(irmngWriter, exportsDir + File.separator + irmngFile, RankType.GENUS);
            indexIRMNG(irmngWriter, "/data/bie-staging/irmng/irmng_species_homonyms.txt", RankType.SPECIES);
            irmngWriter.optimize();
            irmngWriter.close();
        }
        if(generateCommonNames){
            //vernacular index to search for common names
            indexCommonNames(createIndexWriter(new File(indexDir + File.separator + "vernacular"), analyzer), exportsDir);
        }
    }
    /**
     * Creates the temporary index that provides a lookup of checklist bank id to 
     * GUID
     */
    private IndexSearcher createTmpGuidIndex(String cbExportFile) throws Exception{
        System.out.println("Starting to create the tmp guid index...");
        IndexWriter iw = createIndexWriter(new File("/data/tmp/guid"), new KeywordAnalyzer());
        au.com.bytecode.opencsv.CSVReader cbreader = new au.com.bytecode.opencsv.CSVReader(new FileReader(cbExportFile), '\t', '"', '/', 1);
        for (String[] values = cbreader.readNext(); values != null; values = cbreader.readNext()) {
            Document doc = new Document();
            String id = values[POS_ID];
            String guid = values[POS_LSID];
            doc.add(new Field("id", id, Store.YES, Index.NOT_ANALYZED));
            if(StringUtils.isEmpty(id))
                guid = id;
            doc.add(new Field("guid", guid, Store.YES, Index.NO));
            iw.addDocument(doc);
        }
        System.out.println("Finished writing the tmp guid index...");
        iw.commit();
        iw.optimize();
        iw.close();
        return new IndexSearcher(FSDirectory.open(new File("/data/tmp/guid")), true);
    }
    /**
     * Creates an index writer in the specified directory.  It will create/recreate
     * the target directory
     *
     * @param directory
     * @param analyzer
     * @return
     * @throws Exception
     */
    private IndexWriter createIndexWriter(File directory, Analyzer analyzer) throws Exception{

        if (directory.exists()) {
            FileUtils.forceDelete(directory);
        }
        FileUtils.forceMkdir(directory);
        IndexWriter iw = new IndexWriter(FSDirectory.open(directory), analyzer, true, MaxFieldLength.UNLIMITED);
        return iw;
    }
    private String getValueFromIndex(IndexSearcher is, String searchField,String value, String retField){
        TermQuery tq = new TermQuery(new Term(searchField, value));
        try{            
        org.apache.lucene.search.TopDocs results = is.search(tq, 1);
        if(results.totalHits>0)
            return is.doc(results.scoreDocs[0].doc).get(retField);
        }catch(IOException e){e.printStackTrace();}
        return value;
    }

    private void indexALA(IndexWriter iw, String file) throws Exception{
        int records =0;
        long time = System.currentTimeMillis();
        au.com.bytecode.opencsv.CSVReader reader = new au.com.bytecode.opencsv.CSVReader(new FileReader(file), '\t', '"', '\\', 1);
        for (String[] values = reader.readNext(); values != null; values = reader.readNext()) {

            String lsid = values[POS_LSID];
                String id = values[POS_ID];
                String rank = values[POS_RANK];
                int rankId = -1;
                try{
                    rankId =Integer.parseInt(values[POS_RANK_ID]);
                }
                catch(Exception e){}

                String acceptedValues = values[POS_ACC_LSID];
                float boost = 1.0f;
                //give the major ranks a larger boost
                if(rankId % 1000 == 0){
                    boost = 5.0f;
                }
                //if()

            Document doc = createALAIndexDocument(values[POS_SCI_NAME], id, lsid, values[POS_RANK_ID],
                                                values[POS_RANK], values[POS_K], values[POS_KID], values[POS_P],
                                                values[POS_PID], values[POS_C], values[POS_CID],
                                                values[POS_O], values[POS_OID], values[POS_F], values[POS_FID],
                                                values[POS_G], values[POS_GID], values[POS_S], values[POS_SID],
                                                values[POS_LFT],values[POS_RGT],  acceptedValues,
                                                values[POS_SP_EPITHET], values[POS_INFRA_EPITHET], values[POS_AUTHOR],boost);

            

            iw.addDocument(doc);
                    records++;
                    if (records % 100000 == 0) {
                        log.info("Processed " + records + " in " + (System.currentTimeMillis() - time) + " msecs");
                    }
        }
        iw.commit();
        iw.optimize();
        iw.close();
        log.info("Lucene index created - processed a total of " + records + " records in " + (System.currentTimeMillis() - time) + " msecs ");
    }

    /**
     * Create the CB scientific name index
     * @param iw
     * @param cbExportFile
     * @param lexFile
     * @throws Exception
     */
//    private void indexCB(IndexWriter iw, String cbExportFile, String lexFile) throws Exception {
//        long time = System.currentTimeMillis();
//        //CSVReader cbreader = CSVReader.buildReader(new File(cbExportFile), "UTF-8", '\t', '"', 1);
//        au.com.bytecode.opencsv.CSVReader cbreader = new au.com.bytecode.opencsv.CSVReader(new FileReader(cbExportFile), '\t', '"', '/', 1);
//        IndexSearcher gs = createTmpGuidIndex(cbExportFile);
//       CSVReader lexreader =CSVReader.build(new File(lexFile), "UTF-8", "\t", '"', 0);
//        String[] lexName = lexreader.next();//readNext();
//        int unprocessed = 0, records = 0;
//        for (String[] values = cbreader.readNext(); values != null; values = cbreader.readNext()) {
//            //process each line in the file
//
//
//            if (values.length >= 26) {
//                String lsid = values[POS_LSID];
//                String id = values[POS_ID];
//                String rank = values[POS_RANK];
//                String acceptedValues = StringUtils.isEmpty(values[POS_ACC_ID]) ? null : values[POS_ACC_ID] + "\t" + values[POS_ACC_LSID];
//
//                //don't allow subgenus to be processed
//                if (!rank.equals("subgenus")) {
//
//                    //determine whether or not the record represents an australian source
//                    //for now this will be determined using the lsid prefix in the future we may need to move to a more sophisticated method
//                    float boost = 1.0f;
//                    if (lsid.startsWith("urn:lsid:biodiversity.org.au")) {
//                        boost = 2.0f;
//                    }
//
//                    Document doc = buildDocument(values[POS_NAME_CANONICAL], id, lsid, values[POS_RANK_ID],
//                                                values[POS_RANK], values[POS_K], getValueFromIndex(gs,"id",values[POS_KID],"guid"), values[POS_P],
//                                                getValueFromIndex(gs,"id",values[POS_PID],"guid"), values[POS_C], getValueFromIndex(gs,"id",values[POS_CID],"guid"),
//                                                values[POS_O], getValueFromIndex(gs,"id",values[POS_OID],"guid"), values[POS_F], getValueFromIndex(gs,"id",values[POS_FID],"guid"),
//                                                values[POS_G], getValueFromIndex(gs,"id",values[POS_GID],"guid"), values[POS_S], getValueFromIndex(gs,"id",values[POS_SID],"guid"),
//                                                values[POS_LFT],values[POS_RGT], boost, acceptedValues);
//
//                    //Add the alternate names (these are the names that belong to the same lexical group)
//                    TreeSet<String> altNames = new TreeSet<String>();//store a unique set of all the possible alternative names
//
//                    while (lexName != null && Integer.parseInt(lexName[0]) <= Integer.parseInt(id)) {
//                        if (lexName[0].equals(id)) {
//                            //add the full name
//                            altNames.add(lexName[1]);
//                            ParsedName cn = parser.parseIgnoreAuthors(lexName[1]);
//                            if (cn != null && !cn.isHybridFormula()) {
//                                //add the canonical form
//                                altNames.add(cn.buildCanonicalName());
//
//                            }
//                            //addName(doc, lexName[1]);
//                        }
//                        lexName = lexreader.next();//readNext();
//                    }
//                    if (altNames.size() > 0) {
//                        //now add the names to the index
//                        for (String name : altNames) {
//                            doc.add(new Field(IndexField.NAMES.toString(), name, Store.NO, Index.ANALYZED));
//                        }
//                    }
//
//                    iw.addDocument(doc);
//                    records++;
//                    if (records % 100000 == 0) {
//                        log.info("Processed " + records + " in " + (System.currentTimeMillis() - time) + " msecs (Total unprocessed: " + unprocessed + ")");
//                    }
//                }
//                else{
//                    log.debug("Not adding subgenus: " + values[POS_NAME_CANONICAL]);
//                    unprocessed++;
//                }
//            } else {
//                //can't process line without all values
//
//                unprocessed++;
//            }
//        }
//        iw.commit();
//        iw.optimize();
//        iw.close();
//        log.info("Lucene index created - processed a total of " + records + " records in " + (System.currentTimeMillis() - time) + " msecs (Total unprocessed: " + unprocessed + ")");
//    }
    /**
     * Indexes an IRMNG export for use in homonym resolution.
     *
     * @param iw
     * @param irmngExport
     * @throws Exception
     */
    void indexIRMNG(IndexWriter iw, String irmngExport, RankType rank) throws Exception {
        log.info("Creating IRMNG index ...");
        File file = new File(irmngExport);
        if (file.exists()) {
            CSVReader reader = CSVReader.build(file,"UTF-8", "\t", 0);
            int count = 0;
            while (reader.hasNext()) {

                String[] values = reader.next();
                Document doc = new Document();
                if (values != null && values.length >= 7) {
                    doc.add(new Field(RankType.KINGDOM.getRank(), values[0], Store.YES, Index.ANALYZED));
                    doc.add(new Field(RankType.PHYLUM.getRank(), values[1], Store.YES, Index.ANALYZED));
                    doc.add(new Field(RankType.CLASS.getRank(), values[2], Store.YES, Index.ANALYZED));
                    doc.add(new Field(RankType.ORDER.getRank(), values[3], Store.YES, Index.ANALYZED));
                    doc.add(new Field(RankType.FAMILY.getRank(), values[4], Store.YES, Index.ANALYZED));
                    doc.add(new Field(RankType.GENUS.getRank(), values[5], Store.YES, Index.ANALYZED));
                    if(rank == RankType.GENUS){
                        doc.add(new Field(IndexField.ID.toString(), values[6], Store.YES, Index.ANALYZED));//genus id
                        //            doc.add(new Field(, values[7], Store.YES, Index.NOT_ANALYZED));//synonym flag
                        doc.add(new Field(IndexField.ACCEPTED.toString(), values[8], Store.YES, Index.ANALYZED));//synonym id
                        //            doc.add(new Field(,values[9], Store.YES, Index.NOT_ANALYZED)); //synonym name
                        doc.add(new Field(IndexField.HOMONYM.toString(), values[10], Store.YES, Index.ANALYZED)); //homonym flag
                    }
                    else if(rank == RankType.SPECIES){
                        doc.add(new Field(RankType.SPECIES.getRank(), values[6], Store.YES, Index.ANALYZED));
                    }
                    doc.add(new Field(IndexField.RANK.toString(), rank.getRank(), Store.YES, Index.ANALYZED));
                    iw.addDocument(doc);
                    count++;
                }


            }
            iw.commit();

            log.info("Finished indexing " + count + " IRMNG "+rank+" taxa.");
        }
        else
            log.warn("Unable to create IRMNG index.  Can't locate " + irmngExport);
    }
    /**
     * Indexes common names from CoL and ANBG for use in the Common name search.
     * @param iw
     * @param colFileName
     * @param anbgFileName
     * @throws Exception
     */
    private void indexCommonNames(IndexWriter iw,String exportDir)throws Exception{
        log.info("Creating Common Names Index ...");


        File fileCol = new File(exportDir + File.separator + colFile);
        if(fileCol.exists()){
            CSVReader reader = CSVReader.build(fileCol,"UTF-8", "\t", '"', 0);
            int count = 0;
            while (reader.hasNext()) {

                String[] values = reader.next();

                if(values != null && values.length >=4){
                    float boost = 1f;


                    //give a boost to the Australian Common Names in CoL a smaller boost than that of the anbg records
                    if(values[3].equals("T"))
                        boost = 1.5f;
                    iw.addDocument(getCommonNameDocument(values[0],values[1], values[2], boost));
                }
                count++;
            }
            log.info("Finished indexing " + count + " COL Common Names.");
        }
        else
            log.warn("Unable to index CoL Common Names.  Can't locate " + fileCol.getAbsolutePath());

        //process the ANBG common names and add them to the same index
        //create the tmp index for the taxonConcepts used to ensure that a supplied taxon lsid is covered in the export
        IndexSearcher searcher = createTmpIndex(taxonConeptName);

        addAnbgCommonNames(afdFile, iw, searcher);
        addAnbgCommonNames(apniFile, iw, searcher );

        iw.commit();
        iw.optimize();
        iw.close();
    }
    /**
     * Adds an ANBG CSV file of common names to the common name index.
     * @param fileName
     * @param iw
     * @param searcher
     * @throws Exception
     */
    private void addAnbgCommonNames(String fileName, IndexWriter iw, IndexSearcher searcher) throws Exception{
        File namesFile = new File(fileName);
        Pattern p = Pattern.compile(",");
        if(namesFile.exists()){
            CSVReader reader = CSVReader.build(namesFile,"UTF-8","\t", '"' , 1);
            int count = 0;
            while (reader.hasNext()){
                String[] values = reader.next();
                if(values!= null && values.length>= 4){
                //all ANBG records should have the highest boost as they are our authoritive source
                    //we only want to add an ANBG record if the taxon concept LSID exists in the taxonConcepts.txt export
                    if(doesTaxonConceptExist(searcher, values[3])){
                        //each common name could be a comma separated list
                        if(!values[2].contains(",") || values[2].toLowerCase().contains(" and ")){
                            iw.addDocument(getCommonNameDocument(values[2], null,values[3],2.0f));
                            count++;
                        }
                        else{
                            //we need to process each common name in the list
                           String[] names = p.split(values[2]);
                           for(String name : names){
                               iw.addDocument(getCommonNameDocument(name, null,values[3],2.0f));
                               count++;
                           }
                        }
                    }
                    else{
                        System.out.println("Unable to locate LSID " + values[3] + " in current dump");
                    }
                }

            }
            log.info("Finished indexing " + count + " common names from " + fileName);
        }
        else
            log.warn("Unable to index common names. Unable to locate : "+ fileName);
    }
    /**
     * Creates a temporary index that will provide a lookup up of lsid to "real lsid".
     *
     * This deals with the following situations:
     * - common names that are sourced from CoL (LSIDs will be mapped to corresponding ANBG LSID)
     * - Multiple ANBG LSIDs exist for the same scientific name and more than 1 are mapped to the same common name.
     * @param idFile
     * @throws Exception
     */
    private void createExtraIdIndex(String idxLocation, File idFile) throws Exception{
        CSVReader reader = CSVReader.build(idFile, "UTF-8", "\t", '"', 0);
        File indexDir = new File(idxLocation);
        IndexWriter iw = new IndexWriter(FSDirectory.open(indexDir), new KeywordAnalyzer(), true, MaxFieldLength.UNLIMITED);
        while(reader.hasNext()){
            String[] values = reader.next();
            if(values != null && values.length >=3){
                Document doc = new Document();
                doc.add(new Field("lsid", values[2], Store.NO, Index.NOT_ANALYZED));
                doc.add(new Field("reallsid", values[1], Store.YES, Index.NO));
                iw.addDocument(doc);
            }
        }
        iw.commit();
        iw.optimize();
        iw.close();
        idSearcher = new IndexSearcher(FSDirectory.open(indexDir), true);
    }
    /**
     * Creates a temporary index that stores the taxon concept LSIDs that were
     * included in the last ANBG exports.
     *
     * @param tcFileName
     * @return
     * @throws Exception
     */
    private IndexSearcher createTmpIndex(String tcFileName)throws Exception{
        //creating the tmp index in the /tmp/taxonConcept directory
        CSVReader reader = CSVReader.build(new File(tcFileName), "UTF-8", "\t", '"', 1);
        File indexDir = new File("/tmp/taxonConcept");
        IndexWriter iw = new IndexWriter(FSDirectory.open(indexDir), new KeywordAnalyzer(), true, MaxFieldLength.UNLIMITED);
        while(reader.hasNext()){
            String[] values = reader.next();
            if(values!= null && values.length>1){
                //just add the LSID to the index
                Document doc = new Document();
                doc.add(new Field("lsid", values[0], Store.NO, Index.NOT_ANALYZED));
                iw.addDocument(doc);

            }
        }
        iw.commit();
        iw.optimize();
        iw.close();
        return new IndexSearcher(FSDirectory.open(indexDir), true);
    }
    /**
     * Determines whether or not the supplied taxon lsid was included in the
     * latest ANBG exports.
     * @param is
     * @param lsid
     * @return
     */
    private boolean doesTaxonConceptExist(IndexSearcher is, String lsid){
        TermQuery query = new TermQuery(new Term("lsid", lsid));
        try{
            org.apache.lucene.search.TopDocs results = is.search(query, 1);
            return results.totalHits>0;
        }
        catch(IOException e){
            return false;
        }

    }
    /**
     * Uses the id index to find the accepted id for the supplied LSID.
     *
     * When no accepted id can be found the original LSID is returned.
     * @param value
     * @return
     */
    private String getAcceptedLSID(String value){
        TermQuery tq = new TermQuery(new Term("lsid", value));
        try{
        org.apache.lucene.search.TopDocs results = idSearcher.search(tq, 1);
        if(results.totalHits>0)
            return idSearcher.doc(results.scoreDocs[0].doc).get("reallsid");
        }catch(IOException e){}
        return value;
    }
    private Document getCommonNameDocument(String cn, String sn, String lsid,float boost){
        Document doc = new Document();
        //we are only interested in keeping all the alphanumerical values of the common name
        //when searching the same operations will need to be peformed on the search string
        doc.add(new Field(IndexField.COMMON_NAME.toString(), cn.toUpperCase().replaceAll("[^A-Z0-9ÏËÖÜÄÉÈČÁÀÆŒ]", ""), Store.YES, Index.NOT_ANALYZED));
        if(sn != null)
            doc.add(new Field(IndexField.NAME.toString(), sn, Store.YES, Index.ANALYZED));
        String newLsid = getAcceptedLSID(lsid);
        doc.add(new Field(IndexField.LSID.toString(), newLsid, Store.YES, Index.NO));
        doc.setBoost(boost);
        return doc;
    }

    private Document createALAIndexDocument(String name, String id, String lsid, String rank, String rankString,
    		String kingdom, String kid, String phylum, String pid, String clazz, String cid, String order,
                String oid, String family, String fid, String genus, String gid,
    		String species, String sid, String left, String right, String acceptedConcept,String specificEpithet, 
                String infraspecificEpithet, String author,
                float boost){

        Document doc = new Document();
        doc.setBoost(boost);

        //Add the ids
        doc.add(new Field(NameIndexField.ID.toString(), id, Store.YES, Index.NOT_ANALYZED));
        doc.add(new Field(NameIndexField.LSID.toString(), lsid, Store.YES, Index.NOT_ANALYZED));//need to be able to search by LSID with a result from common names


        //Add the scientific name information
        doc.add(new Field(NameIndexField.NAME.toString(), name, Store.YES, Index.ANALYZED));
        

        //rank information
        doc.add(new Field(NameIndexField.RANK_ID.toString(), rank, Store.YES, Index.NOT_ANALYZED));
        doc.add(new Field(NameIndexField.RANK.toString(), rankString, Store.YES, Index.ANALYZED));

        //add the sound expressions for the name if required
        try{
        if(StringUtils.isNotBlank(genus)){
            doc.add(new Field(NameIndexField.GENUS_EX.toString(), TaxonNameSoundEx.treatWord(genus, "genus"), Store.YES, Index.ANALYZED));
        }
        if(StringUtils.isNotBlank(specificEpithet)){
            doc.add(new Field(NameIndexField.SPECIES_EX.toString(), TaxonNameSoundEx.treatWord(specificEpithet, "species"), Store.YES, Index.ANALYZED));
        }
        else if(StringUtils.isNotBlank(genus)){
            doc.add(new Field(NameIndexField.SPECIES_EX.toString(), "<null>", Store.YES, Index.ANALYZED));
        }
        if(StringUtils.isNotBlank(infraspecificEpithet)){
            doc.add(new Field(NameIndexField.INFRA_EX.toString(), TaxonNameSoundEx.treatWord(infraspecificEpithet, "species"), Store.YES, Index.ANALYZED));
        }
        else if(StringUtils.isNotBlank(specificEpithet)){
            //make searching for an empty infraspecific soudex easier
            doc.add(new Field(NameIndexField.INFRA_EX.toString(), "<null>", Store.YES, Index.ANALYZED));
        }
        }
        catch(Exception e){
           // System.out.println(e.getMessage() + " " + name);
            log.warn(lsid + " " +name + " has issues creating a soundex: " + e.getMessage());
        }

        //handle the synonyms
        if (StringUtils.isNotEmpty(acceptedConcept)) {
            doc.add(new Field(NameIndexField.ACCEPTED.toString(), acceptedConcept, Store.YES, Index.NO));
            doc.add(new Field(NameIndexField.iS_SYNONYM.toString(), "T", Store.NO, Index.ANALYZED));
        }
        else{
            doc.add(new Field(NameIndexField.iS_SYNONYM.toString(), "F", Store.NO, Index.ANALYZED));
        }

        //Add the classification information
        if (StringUtils.trimToNull(kingdom) != null) {
                doc.add(new Field(RankType.KINGDOM.getRank(), kingdom, Store.YES, Index.ANALYZED));
                doc.add(new Field("kid", kid, Store.YES, Index.NO));
            }
            if(StringUtils.trimToNull(phylum) != null){
                doc.add(new Field(RankType.PHYLUM.getRank(), phylum, Store.YES, Index.ANALYZED));
                doc.add(new Field("pid", pid, Store.YES, Index.NO));
            }
            if(StringUtils.trimToNull(clazz) != null){
                doc.add(new Field(RankType.CLASS.getRank(), clazz, Store.YES, Index.ANALYZED));
                doc.add(new Field("cid", cid, Store.YES, Index.NO));
            }
            if(StringUtils.trimToNull(order) != null){
                doc.add(new Field(RankType.ORDER.getRank(), order, Store.YES, Index.ANALYZED));
                doc.add(new Field("oid", oid, Store.YES, Index.NO));
            }
            if(StringUtils.trimToNull(family) != null){
                doc.add(new Field(RankType.FAMILY.getRank(), family, Store.YES, Index.ANALYZED));
                doc.add(new Field("fid",fid, Store.YES, Index.NO));
            }
            if (StringUtils.trimToNull(genus) != null){
                doc.add(new Field(RankType.GENUS.getRank(), genus, Store.YES, Index.ANALYZED));
                doc.add(new Field("gid", gid, Store.YES, Index.NO));
            }
            if(StringUtils.trimToNull(species) != null){
                doc.add(new Field(RankType.SPECIES.getRank(), species, Store.YES, Index.ANALYZED));
                doc.add(new Field("sid", sid, Store.YES, Index.NO));
            }
            if(StringUtils.trimToNull(left) != null)
                doc.add(new Field("left", left, Store.YES, Index.NOT_ANALYZED));
            if(StringUtils.trimToNull(right) != null)
                doc.add(new Field("right", right, Store.YES, Index.NOT_ANALYZED));


        //Add the author information
        if(StringUtils.isNotEmpty(author)){
            //TODO think about whether we need to treat the author string with the taxamatch
            doc.add(new Field(NameIndexField.AUTHOR.toString(), author, Store.YES, Index.ANALYZED));
        }


        //Generate the canonical
        //add the canonical form of the name
        try{
        ParsedName cn = parser.parse(name);
            //if(cn != null && !cn.hasProblem() && !cn.isIndetermined()){
            if(cn != null && cn.isParsableType()&& !cn.isIndetermined() 
            && cn.getType()!= NameType.informal)// a scientific name with some informal addition like "cf." or indetermined like Abies spec.
            {
               doc.add(new Field(NameIndexField.NAME.toString(), cn.canonicalName(), Store.YES, Index.ANALYZED));
               if(specificEpithet == null && cn.isBinomial()){
                   //check to see if we need to determine the epithets from the parse
                   genus = cn.getGenusOrAbove();
                   if(specificEpithet == null) specificEpithet = cn.getSpecificEpithet();
                   if(infraspecificEpithet == null)infraspecificEpithet = cn.getInfraSpecificEpithet();
               }
            }
            //check to see if the concept represents a phrase name
            if(cn instanceof ALAParsedName){
                ALAParsedName alapn = (ALAParsedName)cn;
                if((!"sp.".equals(alapn.rank)) && alapn.specificEpithet != null)
                    doc.add(new Field(NameIndexField.SPECIFIC.toString(), alapn.getSpecificEpithet(), Store.YES, Index.ANALYZED_NO_NORMS));
                else if((!"sp.".equals(alapn.rank)) && alapn.specificEpithet == null){
                    log.warn( lsid + " " +name + " has an empty specific for non sp. phrase");
                }
                if(StringUtils.trimToNull(alapn.getLocationPhraseDesciption()) != null)
                    doc.add(new Field(NameIndexField.PHRASE.toString(), alapn.cleanPhrase, Store.YES, Index.ANALYZED_NO_NORMS));
                    //doc.add(new Field(NameIndexField.PHRASE.toString(), alapn.getLocationPhraseDesciption(), Store.YES, Index.ANALYZED_NO_NORMS));
                if(alapn.getPhraseVoucher() != null)
                    doc.add(new Field(NameIndexField.VOUCHER.toString(), alapn.cleanVoucher, Store.YES,Index.ANALYZED_NO_NORMS));
                if(StringUtils.isBlank(genus) && StringUtils.isNotBlank(alapn.getGenusOrAbove())){
                    //add the genus to the index as it is necessary to match on the phrase name.
                     doc.add(new Field(RankType.GENUS.getRank(), alapn.getGenusOrAbove(), Store.YES, Index.ANALYZED));
                }
                    //doc.add(new Field(NameIndexField.VOUCHER.toString(), CBIndexSearch.voucherRemovePattern.matcher(alapn.getPhraseVoucher()).replaceAll(""), Store.YES,Index.ANALYZED_NO_NORMS));
            }
        }
        catch(org.gbif.ecat.parser.UnparsableException e){
            //check to see if the name is a virus in which case an extra name is added without the virus key word
            if(e.type == NameType.virus)
                doc.add(new Field(NameIndexField.NAME.toString(), au.org.ala.checklist.lucene.CBIndexSearch.virusStopPattern.matcher(name).replaceAll(" "), Store.YES, Index.ANALYZED));

        }
        catch(Exception e){
            e.printStackTrace();
            //throw e;
        }

        

        return doc;

    }

    private String getPhraseName(String specificEpithet, String infraspecificEpithet){
        
        return null;
    }


    /**
     * Builds and returns the initial document
     * @param key
     * @param value
     * @param id
     * @param rank
     * @param rankString
     * @return
     */
//    private Document buildDocument(String name, String id, String lsid, String rank, String rankString,
//    		String kingdom, String kid, String phylum, String pid, String clazz, String cid, String order,
//                String oid, String family, String fid, String genus, String gid,
//    		String species, String sid, String left, String right, float boost, String acceptedConcept) {
////        System.out.println("creating index " + name + " " + classification + " " + id + " " + lsid + " " + rank + " " + rankString+ " " + kingdom + " " + genus);
//        Document doc = new Document();
//        Field nameField = new Field(IndexField.NAME.toString(), name, Store.YES, Index.ANALYZED);
//        nameField.setBoost(boost); //only want to apply the boost when searching on a name
//        doc.add(nameField);
//        doc.add(new Field(IndexField.ID.toString(), id, Store.YES, Index.NOT_ANALYZED));
//        doc.add(new Field(IndexField.RANK.toString(), rank, Store.YES, Index.NOT_ANALYZED));
//        doc.add(new Field(IndexField.RANK.toString(), rankString, Store.YES, Index.ANALYZED));
//
//        doc.add(new Field(IndexField.LSID.toString(), lsid, Store.YES, Index.NOT_ANALYZED));//need to be able to search by LSID with a result from common names
//
//        //add a search_canonical for the record
//        doc.add(new Field(IndexField.SEARCHABLE_NAME.toString(), tnse.soundEx(name), Store.NO, Index.NOT_ANALYZED));
//        if (StringUtils.isNotEmpty(acceptedConcept)) {
//            doc.add(new Field(IndexField.ACCEPTED.toString(), acceptedConcept, Store.YES, Index.NO));
//            //when the rank if genus or below use the Name Parser to get access to the correct Genus name to check for homonyms
//            try{
//            ParsedName pn = parser.parse(name);
//            try{
//            if (rankString !=null &&RankType.getAllRanksBelow(RankType.GENUS.getId()).contains(RankType.getForName(rankString)) ) {
//                if(pn != null)
//                    genus = pn.getGenusOrAbove();
//                else{
//                    genus = null;
//                    //System.out.println("Name: " + name + " pn: "+ pn + " rank: "+rankString);
//                }
//            } else {
//                genus = null;
//            }
//            }
//            catch(NullPointerException npe){
//                //System.out.println("Unknown rank : " + rankString);
//            }
//            }
//            catch(org.gbif.ecat.parser.UnparsableException e){
//
//            }
//
//        } else {
//            if (StringUtils.trimToNull(kingdom) != null) {
//                doc.add(new Field(RankType.KINGDOM.getRank(), kingdom, Store.YES, Index.ANALYZED));
//                doc.add(new Field("kid", kid, Store.YES, Index.NO));
//            }
//            if(StringUtils.trimToNull(phylum) != null){
//                doc.add(new Field(RankType.PHYLUM.getRank(), phylum, Store.YES, Index.ANALYZED));
//                doc.add(new Field("pid", pid, Store.YES, Index.NO));
//            }
//            if(StringUtils.trimToNull(clazz) != null){
//                doc.add(new Field(RankType.CLASS.getRank(), clazz, Store.YES, Index.ANALYZED));
//                doc.add(new Field("cid", cid, Store.YES, Index.NO));
//            }
//            if(StringUtils.trimToNull(order) != null){
//                doc.add(new Field(RankType.ORDER.getRank(), order, Store.YES, Index.ANALYZED));
//                doc.add(new Field("oid", oid, Store.YES, Index.NO));
//            }
//            if(StringUtils.trimToNull(family) != null){
//                doc.add(new Field(RankType.FAMILY.getRank(), family, Store.YES, Index.ANALYZED));
//                doc.add(new Field("fid",fid, Store.YES, Index.NO));
//            }
//            if (StringUtils.trimToNull(genus) != null){
//                doc.add(new Field(RankType.GENUS.getRank(), genus, Store.YES, Index.ANALYZED));
//                doc.add(new Field("gid", gid, Store.YES, Index.NO));
//            }
//            if(StringUtils.trimToNull(species) != null){
//                doc.add(new Field(RankType.SPECIES.getRank(), species, Store.YES, Index.ANALYZED));
//                doc.add(new Field("sid", sid, Store.YES, Index.NO));
//            }
//            if(StringUtils.trimToNull(left) != null)
//                doc.add(new Field("left", left, Store.YES, Index.NOT_ANALYZED));
//            if(StringUtils.trimToNull(right) != null)
//                doc.add(new Field("right", right, Store.YES, Index.NOT_ANALYZED));
//        }
//        return doc;
//    }

    /**
     * Generates the Lucene index required for the name matching API.
     * eg
     * au.org.ala.checklist.lucene.CBCreateLuceneIndex "/data/exports" "/data/lucene/namematching"
     *  Extra optional args that should appear after the directory names
     * -sn: Only create the indexes necessary for the scientific name lookups
     * -cn: Only create the indexes necessary for the common name lookups
     * @param args
     * @throws Exception
     */
    public static void main(String[] args) throws Exception {
        CBCreateLuceneIndex indexer = new CBCreateLuceneIndex();
        indexer.init();

        if (args.length >= 2) {
            boolean sn = true;
            boolean cn = true;
            if(args.length ==3){
                sn = args[2].equals("-sn");
                cn = args[2].equals("-cn");
            }
            indexer.createIndex(args[0], args[1], sn, cn);
        } else {
            indexer.createIndex("/data/names/Version2011", "/data/lucene/namematchingv1_1", true, false);
            //System.out.println("au.org.ala.checklist.lucene.CBCreateLuceneIndex <directory with export files> <directory in which to create indexes>");
           //indexer.createIndex("/data/exports/cb", "/data/lucene/namematching", false, true);

        }
    }
}
