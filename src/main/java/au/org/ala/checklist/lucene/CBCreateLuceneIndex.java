package au.org.ala.checklist.lucene;

import au.org.ala.data.util.RankType;
import java.io.BufferedReader;
import java.io.File;
import java.io.IOException;

import java.io.InputStreamReader;
import java.util.HashSet;

import java.util.Set;
import java.util.TreeSet;
import java.util.regex.Pattern;
import javax.sql.DataSource;
import org.apache.commons.io.FileUtils;
import org.apache.commons.io.LineIterator;
import org.apache.commons.lang.StringUtils;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.apache.lucene.analysis.KeywordAnalyzer;
import org.apache.lucene.document.Document;
import org.apache.lucene.document.Field;
import org.apache.lucene.document.Field.Index;
import org.apache.lucene.document.Field.Store;
import org.apache.lucene.index.IndexWriter;
import org.apache.lucene.index.IndexWriter.MaxFieldLength;
import org.apache.lucene.index.Term;
import org.apache.lucene.search.IndexSearcher;
import org.apache.lucene.search.TermQuery;

import org.apache.lucene.store.FSDirectory;
import org.gbif.ecat.model.ParsedName;
import org.gbif.ecat.parser.NameParser;
import org.gbif.file.CSVReader;
import org.springframework.context.ApplicationContext;
import org.springframework.context.support.ClassPathXmlApplicationContext;
import org.springframework.jdbc.core.JdbcTemplate;
import org.gbif.portal.util.taxonomy.TaxonNameSoundEx;

/**
 * Creates the Lucene index based on the cb_names export generated by ChecklistBankExporter
 * 
 * @author Natasha
 */
public class CBCreateLuceneIndex {

    protected String cbExportFile = "cb_name_usages.txt";
    protected String lexFile = "cb_lex_names.txt";
    protected String irmngFile = "irmng_classification.txt";
    protected String colFile = "col_common_names.txt";
    protected String afdFile = "/data/bie-staging/anbg/AFD-common-names.csv";
    protected String apniFile = "/data/bie-staging/anbg/APNI-common-names.csv";
    protected String taxonConeptName = "/data/bie-staging/anbg/taxonConcepts.txt";
    protected Log log = LogFactory.getLog(CBCreateLuceneIndex.class);
    protected ApplicationContext context;
    protected DataSource dataSource;
    protected JdbcTemplate dTemplate;
    private IndexSearcher idSearcher;
    //the position in the line for each of the required values
    //nub id\tparent nub id\tlsid\tsynonym id\tsynonym lsid\tname id\tcanonical name\tauthor\tportal rank id\trank\tlft\trgt\tkingdom id\tkingdom\tphylum id\tphylum\tclass id\tclass\torder id \torder\tfamily id\tfamily\tgenus id\tgenus\tspecies id\tspecies
    private final int POS_ID = 0;
    private final int POS_LSID = 2;
    private final int POS_ACC_ID = 3;
    private final int POS_ACC_LSID = 4;
    private final int POS_NAME_ID = 5;
    private final int POS_NAME = 6;
    private final int POS_RANK_ID = 8;
    private final int POS_RANK = 9;
    private final int POS_KID = 12;
    private final int POS_K = 13;
    private final int POS_PID = 14;
    private final int POS_P = 15;
    private final int POS_CID = 16;
    private final int POS_C = 17;
    private final int POS_OID = 18;
    private final int POS_O = 19;
    private final int POS_FID = 20;
    private final int POS_F = 21;
    private final int POS_GID = 22;
    private final int POS_G = 23;
    private final int POS_SID = 24;
    private final int POS_S = 25;

    //Fields that are being indexed or stored in the lucene index
    public enum IndexField {

        NAME("name"),
        NAMES("names"),
        ID("id"),
        RANK("rank"),
        SEARCHABLE_NAME("searchcan"),
        LSID("lsid"),
        HOMONYM("homonym"),
        ACCEPTED("synonym"),
        COMMON_NAME("common");

        String name;

        IndexField(String name) {
            this.name = name;
        }

        public String toString() {
            return name;
        }
    };
    NameParser parser = new NameParser();
    Set<String> knownHomonyms = new HashSet<String>();   
    private TaxonNameSoundEx tnse;

    public void init() throws Exception {
        String[] locations = {"classpath*:au/org/ala/**/applicationContext-cb*.xml"};
        context = new ClassPathXmlApplicationContext(locations);
        dataSource = (DataSource) context.getBean("cbDataSource");
        dTemplate = new JdbcTemplate(dataSource);
        tnse = new TaxonNameSoundEx();
        // init the known homonyms
        LineIterator lines = new LineIterator(new BufferedReader(
                new InputStreamReader(
                this.getClass().getClassLoader().getResource(
                "au/org/ala/propertystore/known_homonyms.txt").openStream(), "ISO-8859-1")));
        while (lines.hasNext()) {
            String line = lines.nextLine().trim();
            knownHomonyms.add(line.toUpperCase());
        }
    }

    /**
     * Creates the index from the specified checklist bank names usage export file into
     * the specified index directory.
     * 
     * @param cbExportFile A cb export file as generated from the ChecklistBankExporter
     * @param lexFile
     * @param irmngFile
     * @param indexDir The directory in which the 2 indices will be created.
     * @throws Exception
     */
    public void createIndex(String exportsDir, String indexDir, boolean generateSciNames, boolean generateCommonNames) throws Exception {

        KeywordAnalyzer analyzer = new KeywordAnalyzer();
        //generate the extra id index
        createExtraIdIndex(indexDir + File.separator + "id",new File(exportsDir + File.separator + "cb_identifiers.txt"));
        if(generateSciNames){
            //Checklist Bank Main Index
            indexCB(createIndexWriter(new File(indexDir + File.separator + "cb"), analyzer), exportsDir + File.separator + cbExportFile, exportsDir + File.separator + lexFile);
            //IRMNG index to aid in the resolving of homonyms
            indexIRMNG(createIndexWriter(new File(indexDir + File.separator + "irmng"), analyzer), exportsDir + File.separator + irmngFile);
        }
        if(generateCommonNames){
            //vernacular index to search for common names
            indexCommonNames(createIndexWriter(new File(indexDir + File.separator + "vernacular"), analyzer), exportsDir);
        }
    }
    /**
     * Creates an index writer in the specified directory.  It will create/recreate
     * the target directory
     * 
     * @param directory
     * @param analyzer
     * @return
     * @throws Exception
     */
    private IndexWriter createIndexWriter(File directory, KeywordAnalyzer analyzer) throws Exception{

        if (directory.exists()) {
            FileUtils.forceDelete(directory);
        }
        FileUtils.forceMkdir(directory);
        IndexWriter iw = new IndexWriter(FSDirectory.open(directory), analyzer, true, MaxFieldLength.UNLIMITED);
        return iw;
    }

    /**
     * Create the CB scientific name index
     * @param iw
     * @param cbExportFile
     * @param lexFile
     * @throws Exception
     */
    private void indexCB(IndexWriter iw, String cbExportFile, String lexFile) throws Exception {
        long time = System.currentTimeMillis();
        CSVReader cbreader = CSVReader.buildReader(new File(cbExportFile), "UTF-8", '\t', '"', 1);

        CSVReader lexreader = CSVReader.buildReader(new File(lexFile), "UTF-8", '\t', '"', 0);
        String[] lexName = lexreader.readNext();
        int unprocessed = 0, records = 0;
        for (String[] values = cbreader.readNext(); values != null; values = cbreader.readNext()) {
            //process each line in the file


            if (values.length >= 26) {
                String lsid = values[POS_LSID];
                String id = values[POS_ID];
                String acceptedValues = StringUtils.isEmpty(values[POS_ACC_ID]) ? null : values[POS_ACC_ID] + "\t" + values[POS_ACC_LSID];

                //determine whether or not the record represents an australian source
                //for now this will be determined using the lsid prefix in the future we may need to move to a more sophisticated method
                float boost = 1.0f;
                if (lsid.startsWith("urn:lsid:biodiversity.org.au")) {
                    boost = 2.0f;
                }

                Document doc = buildDocument(values[POS_NAME], id, lsid, values[POS_RANK_ID], values[POS_RANK], values[POS_K], values[POS_P], values[POS_C], values[POS_O], values[POS_F], values[POS_G], values[POS_S], boost, acceptedValues);//buildDocument(rec.value("http://rs.tdwg.org/dwc/terms/ScientificName"), classification, id, lsid, rec.value("rankID"), rec.value("http://rs.tdwg.org/dwc/terms/TaxonRank"), rec.value("http://rs.tdwg.org/dwc/terms/kingdom"), rec.value("http://rs.tdwg.org/dwc/terms/phylum"), rec.value("http://rs.tdwg.org/dwc/terms/genus"), boost, synonymValues);

                //Add the alternate names (these are the names that belong to the same lexical group)
                TreeSet<String> altNames = new TreeSet<String>();//store a unique set of all the possible alternative names

                while (lexName != null && Integer.parseInt(lexName[0]) <= Integer.parseInt(id)) {
                    if (lexName[0].equals(id)) {
                        //add the full name
                        altNames.add(lexName[1]);
                        ParsedName cn = parser.parseIgnoreAuthors(lexName[1]);
                        if(cn!=null && !cn.isHybridFormula()){
                            //add the canonical form
                            altNames.add(cn.buildCanonicalName());
                            
                        }
                        //addName(doc, lexName[1]);
                    }
                    lexName = lexreader.readNext();
                }
                if(altNames.size()>0){
                    //now add the names to the index
                    for(String name: altNames){
                        doc.add(new Field(IndexField.NAMES.toString(), name, Store.NO, Index.NOT_ANALYZED));
                    }
                }
               
                iw.addDocument(doc);
                records++;
                if (records % 100000 == 0) {
                    log.info("Processed " + records + " in " + (System.currentTimeMillis() - time) + " msecs (Total unprocessed: " + unprocessed + ")");
                }
            } else {
                //can't process line without all values

                unprocessed++;
            }
        }
        iw.commit();
        iw.optimize();
        iw.close();
        log.info("Lucene index created - processed a total of " + records + " records in " + (System.currentTimeMillis() - time) + " msecs (Total unprocessed: " + unprocessed + ")");
    }
    /**
     * Indexes an IRMNG export for use in homonym resolution.
     * 
     * @param iw
     * @param irmngExport
     * @throws Exception
     */
    void indexIRMNG(IndexWriter iw, String irmngExport) throws Exception {
        log.info("Creating IRMNG index ...");
        File file = new File(irmngExport);
        if (file.exists()) {
            CSVReader reader = CSVReader.buildReader(file, 0);
            int count = 0;
            while (reader.hasNext()) {

                String[] values = reader.readNext();
                Document doc = new Document();
                if (values != null && values.length >= 11) {
                    doc.add(new Field(RankType.KINGDOM.getRank(), values[0], Store.YES, Index.NOT_ANALYZED));
                    doc.add(new Field(RankType.PHYLUM.getRank(), values[1], Store.YES, Index.NOT_ANALYZED));
                    doc.add(new Field(RankType.CLASS.getRank(), values[2], Store.YES, Index.NOT_ANALYZED));
                    doc.add(new Field(RankType.ORDER.getRank(), values[3], Store.YES, Index.NOT_ANALYZED));
                    doc.add(new Field(RankType.FAMILY.getRank(), values[4], Store.YES, Index.NOT_ANALYZED));
                    doc.add(new Field(RankType.GENUS.getRank(), values[5], Store.YES, Index.NOT_ANALYZED));
                    doc.add(new Field(IndexField.ID.toString(), values[6], Store.YES, Index.NOT_ANALYZED));//genus id
                    //            doc.add(new Field(, values[7], Store.YES, Index.NOT_ANALYZED));//synonym flag
                    doc.add(new Field(IndexField.ACCEPTED.toString(), values[8], Store.YES, Index.NOT_ANALYZED));//synonym id
                    //            doc.add(new Field(,values[9], Store.YES, Index.NOT_ANALYZED)); //synonym name
                    doc.add(new Field(IndexField.HOMONYM.toString(), values[10], Store.YES, Index.NOT_ANALYZED)); //homonym flag
                    iw.addDocument(doc);
                    count++;
                }


            }
            iw.commit();
            iw.optimize();
            iw.close();
            log.info("Finished indexing " + count + " IRMNG taxa.");
        }
        else
            log.warn("Unable to create IRMNG index.  Can't locate " + irmngExport);
    }
    /**
     * Indexes common names from CoL and ANBG for use in the Common name search.
     * @param iw
     * @param colFileName
     * @param anbgFileName
     * @throws Exception
     */
    private void indexCommonNames(IndexWriter iw,String exportDir)throws Exception{
        log.info("Creating Common Names Index ...");
        

        File fileCol = new File(exportDir + File.separator + colFile);
        if(fileCol.exists()){    
            CSVReader reader = CSVReader.buildReader(fileCol, 0);
            int count = 0;
            while (reader.hasNext()) {

                String[] values = reader.readNext();
                
                if(values != null && values.length >=4){
                    float boost = 1f;

                    
                    //give a boost to the Australian Common Names in CoL a smaller boost than that of the anbg records
                    if(values[3].equals("T"))
                        boost = 1.5f;
                    iw.addDocument(getCommonNameDocument(values[0],values[1], values[2], boost));
                }
                count++;
            }
            log.info("Finished indexing " + count + " COL Common Names.");
        }
        else
            log.warn("Unable to index CoL Common Names.  Can't locate " + fileCol.getAbsolutePath());
        
        //process the ANBG common names and add them to the same index
        //create the tmp index for the taxonConcepts used to ensure that a supplied taxon lsid is covered in the export
        IndexSearcher searcher = createTmpIndex(taxonConeptName);

        addAnbgCommonNames(afdFile, iw, searcher);
        addAnbgCommonNames(apniFile, iw, searcher );
        
        iw.commit();
        iw.optimize();
        iw.close();
    }
    /**
     * Adds an ANBG CSV file of common names to the common name index.
     * @param fileName
     * @param iw
     * @param searcher
     * @throws Exception
     */
    private void addAnbgCommonNames(String fileName, IndexWriter iw, IndexSearcher searcher) throws Exception{
        File namesFile = new File(fileName);
        Pattern p = Pattern.compile(",");
        if(namesFile.exists()){
            CSVReader reader = CSVReader.buildReader(namesFile,"UTF-8",',', '"' , 0);
            int count = 0;
            while (reader.hasNext()){
                String[] values = reader.readNext();
                if(values!= null && values.length>= 10){
                //all ANBG records should have the highest boost as they are our authoritive source
                    //we only want to add an ANBG record if the taxon concept LSID exists in the taxonConcepts.txt export
                    if(doesTaxonConceptExist(searcher, values[5])){
                        //each common name could be a comma separated list
                        if(!values[2].contains(",") || values[2].toLowerCase().contains(" and ")){
                            iw.addDocument(getCommonNameDocument(values[2], values[7],values[5],2.0f));
                            count++;
                        }
                        else{
                            //we need to process each common name in the list
                           String[] names = p.split(values[2]);
                           for(String name : names){
                               iw.addDocument(getCommonNameDocument(name, values[7],values[5],2.0f));
                               count++;
                           }
                        }
                    }
                }

            }
            log.info("Finished indexing " + count + " common names from " + fileName);
        }
        else
            log.warn("Unable to index common names. Unable to locate : "+ fileName);
    }
    /**
     * Creates a temporary index that will provide a lookup up of lsid to "real lsid".
     * 
     * This deals with the following situations:
     * - common names that are sourced from CoL (LSIDs will be mapped to corresponding ANBG LSID)
     * - Multiple ANBG LSIDs exist for the same scientific name and more than 1 are mapped to the same common name.
     * @param idFile
     * @throws Exception
     */
    private void createExtraIdIndex(String idxLocation, File idFile) throws Exception{
        CSVReader reader = CSVReader.buildReader(idFile, "UTF-8", '\t', '"', 0);
        File indexDir = new File(idxLocation);
        IndexWriter iw = new IndexWriter(FSDirectory.open(indexDir), new KeywordAnalyzer(), true, MaxFieldLength.UNLIMITED);
        while(reader.hasNext()){
            String[] values = reader.readNext();
            if(values != null && values.length >=3){
                Document doc = new Document();
                doc.add(new Field("lsid", values[2], Store.NO, Index.NOT_ANALYZED));
                doc.add(new Field("reallsid", values[1], Store.YES, Index.NO));
                iw.addDocument(doc);
            }
        }
        iw.commit();
        iw.optimize();
        iw.close();
        idSearcher = new IndexSearcher(FSDirectory.open(indexDir), true);
    }
    /**
     * Creates a temporory index that stores the taxon concept LSIDs that were
     * included in the last ANBG exports.
     * 
     * @param tcFileName
     * @return
     * @throws Exception
     */
    private IndexSearcher createTmpIndex(String tcFileName)throws Exception{
        //creating the tmp index in the /tmp/taxonConcept directory
        CSVReader reader = CSVReader.buildReader(new File(tcFileName), "UTF-8", '\t', '"', 0);
        File indexDir = new File("/tmp/taxonConcept");
        IndexWriter iw = new IndexWriter(FSDirectory.open(indexDir), new KeywordAnalyzer(), true, MaxFieldLength.UNLIMITED);
        while(reader.hasNext()){
            String[] values = reader.readNext();
            if(values!= null && values.length>1){
                //just add the LSID to the index
                Document doc = new Document();
                doc.add(new Field("lsid", values[0], Store.NO, Index.NOT_ANALYZED));
                iw.addDocument(doc);
                
            }
        }
        iw.commit();
        iw.optimize();
        iw.close();
        return new IndexSearcher(FSDirectory.open(indexDir), true);
    }
    /**
     * Determines whether or not the supplied taxon lsid was included in the
     * latest ANBG exports. 
     * @param is
     * @param lsid
     * @return
     */
    private boolean doesTaxonConceptExist(IndexSearcher is, String lsid){
        TermQuery query = new TermQuery(new Term("lsid", lsid));
        try{
            org.apache.lucene.search.TopDocs results = is.search(query, 1);
            return results.totalHits>0;
        }
        catch(IOException e){
            return false;
        }

    }
    /**
     * Uses the id index to find the accepted id for the supplied LSID.
     *
     * When no accepted id can be found the original LSID is returned.
     * @param value
     * @return
     */
    private String getAcceptedLSID(String value){
        TermQuery tq = new TermQuery(new Term("lsid", value));
        try{
        org.apache.lucene.search.TopDocs results = idSearcher.search(tq, 1);
        if(results.totalHits>0)
            return idSearcher.doc(results.scoreDocs[0].doc).get("reallsid");
        }catch(IOException e){}
        return value;
    }
    private Document getCommonNameDocument(String cn, String sn, String lsid,float boost){
        Document doc = new Document();
        //we are only interested in keeping all the alphanumerical values of the common name
        //when searching the same operations will need to be peformed on the search string
        doc.add(new Field(IndexField.COMMON_NAME.toString(), cn.toUpperCase().replaceAll("[^A-Z0-9ÏËÖÜÄÉÈČÁÀÆŒ]", ""), Store.YES, Index.NOT_ANALYZED));
        doc.add(new Field(IndexField.NAME.toString(), sn, Store.YES, Index.NOT_ANALYZED));
        String newLsid = getAcceptedLSID(lsid);
        doc.add(new Field(IndexField.LSID.toString(), newLsid, Store.YES, Index.NO));
        doc.setBoost(boost);
        return doc;
    }
    /**
     * Builds and returns the initial document
     * @param key
     * @param value
     * @param id
     * @param rank
     * @param rankString
     * @return
     */
    private Document buildDocument(String name, String id, String lsid, String rank, String rankString, String kingdom, String phylum, String clazz, String order, String family, String genus, String species, float boost, String acceptedConcept) {
//        System.out.println("creating index " + name + " " + classification + " " + id + " " + lsid + " " + rank + " " + rankString+ " " + kingdom + " " + genus);
        Document doc = new Document();
        Field nameField = new Field(IndexField.NAME.toString(), name, Store.NO, Index.NOT_ANALYZED);
        nameField.setBoost(boost); //only want to apply the boost when searching on a name
        doc.add(nameField);
        doc.add(new Field(IndexField.ID.toString(), id, Store.YES, Index.NOT_ANALYZED));
        doc.add(new Field(IndexField.RANK.toString(), rank, Store.YES, Index.NOT_ANALYZED));
        doc.add(new Field(IndexField.RANK.toString(), rankString, Store.YES, Index.NOT_ANALYZED));

        doc.add(new Field(IndexField.LSID.toString(), lsid, Store.YES, Index.NOT_ANALYZED));//need to be able to search by LSID with a result from common names

        //add a search_canonical for the record
        doc.add(new Field(IndexField.SEARCHABLE_NAME.toString(), tnse.soundEx(name), Store.NO, Index.NOT_ANALYZED));
        if (acceptedConcept != null) {
            doc.add(new Field(IndexField.ACCEPTED.toString(), acceptedConcept, Store.YES, Index.NO));
            //when the rank if genus or below use the Name Parser to get access to the correct Genus name to check for homonyms
            ParsedName pn = parser.parseIgnoreAuthors(name);
            try{
            if (rankString !=null &&RankType.getAllRanksBelow(RankType.GENUS.getId()).contains(RankType.getForName(rankString)) ) {
                if(pn != null)
                    genus = pn.getGenusOrAbove();
                else{
                    genus = null;
                    //System.out.println("Name: " + name + " pn: "+ pn + " rank: "+rankString);
                }
            } else {
                genus = null;
            }
            }
            catch(NullPointerException npe){
                System.out.println("Unknown rank : " + rankString);
            }

        } else {
            if (StringUtils.trimToNull(kingdom) != null) {
                doc.add(new Field(RankType.KINGDOM.getRank(), kingdom, Store.YES, Index.NOT_ANALYZED));
            }
            if(StringUtils.trimToNull(phylum) != null)
                doc.add(new Field(RankType.PHYLUM.getRank(), phylum, Store.YES, Index.NOT_ANALYZED));
            if(StringUtils.trimToNull(clazz) != null)
                doc.add(new Field(RankType.CLASS.getRank(), clazz, Store.YES, Index.NOT_ANALYZED));
            if(StringUtils.trimToNull(order) != null)
                doc.add(new Field(RankType.ORDER.getRank(), order, Store.YES, Index.NOT_ANALYZED));
            if(StringUtils.trimToNull(family) != null)
                doc.add(new Field(RankType.FAMILY.getRank(), family, Store.YES, Index.NOT_ANALYZED));
            if (StringUtils.trimToNull(genus) != null) {
                doc.add(new Field(RankType.GENUS.getRank(), genus, Store.YES, Index.NOT_ANALYZED));

            }
            if(StringUtils.trimToNull(species) != null){
                doc.add(new Field(RankType.SPECIES.getRank(), species, Store.YES, Index.NOT_ANALYZED));
            }
        }
        return doc;
    }

    /**
     * Generates the Lucene index required for the name matching API.
     * eg
     * au.org.ala.checklist.lucene.CBCreateLuceneIndex "/data/exports" "/data/lucene/namematching"
     *  Extra optional args that should appear after the directory names
     * -sn: Only create the indexes necessary for the scientific name lookups
     * -cn: Only create the indexes necessary for the common name lookups
     * @param args
     * @throws Exception
     */
    public static void main(String[] args) throws Exception {
        CBCreateLuceneIndex indexer = new CBCreateLuceneIndex();
        indexer.init();
        if (args.length >= 2) {
            boolean sn = true;
            boolean cn = true;
            if(args.length ==3){
                sn = args[2].equals("-sn");
                cn = args[2].equals("-cn");
            }
            indexer.createIndex(args[0], args[1], sn, cn);
        } else {
            System.out.println("au.org.ala.checklist.lucene.CBCreateLuceneIndex <directory with export files> <directory in which to create indexes>");
           //indexer.createIndex("/data/exports/cb", "/data/lucene/namematching", false, true);
            
        }
    }
}
